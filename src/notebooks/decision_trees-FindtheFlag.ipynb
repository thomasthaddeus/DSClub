{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SCIENTIST: NATURAL LANGUAGE PROCESSING SPECIALIST\n",
    "\n",
    "## Find the flag!\n",
    "\n",
    "Can you guess which continent this flag comes from?\n",
    "\n",
    "## Flag of Reunion\n",
    "\n",
    "What are some of the features that would clue you in? Maybe some of the colors are good indicators. The presence or absence of certain shapes could give you a hint. In this project, we’ll use decision trees to try to predict the continent of flags based on several of these features.\n",
    "\n",
    "We'll explore which features are the best to use and the best way to create your decision tree.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "The original data set is available at the [UCI Machine Learning Repository][uci]\n",
    "\n",
    "## Tasks\n",
    "\n",
    "[uci]: https://archive.ics.uci.edu/ml/datasets/Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the data\n",
    "\n",
    "1. The dataset has been loaded for you in script.py and saved as a dataframe named df. Some of the input and output features of interest are:\n",
    "\n",
    "    - **name**: Name of the country concerned\n",
    "    - **landmass**: 1=N.America, 2=S.America, 3=Europe, 4=Africa, 5=Asia, 6=Oceania\n",
    "    - **bars**: Number of vertical bars in the flag\n",
    "    - **stripes**: Number of horizontal stripes in the flag\n",
    "    - **colours**: Number of different colours in the flag\n",
    "    - red: 0 if red absent, 1 if red present in the flag\n",
    "\n",
    "    - **mainhue**: predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue, and if that fails the leftmost hue)\n",
    "    - **circles**: Number of circles in the flag\n",
    "    - **crosses**: Number of (upright) crosses\n",
    "    - **saltires**: Number of diagonal crosses\n",
    "    - **quarters**: Number of quartered sections\n",
    "    - **sunstars**: Number of sun or star symbols\n",
    "\n",
    "    We will build a decision tree classifier to predict what continent a particular flag comes from. Before that, we want to understand the distribution of flags by continent. Calcluate the count of flags by landmass value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmass\n",
      "4    52\n",
      "5    39\n",
      "3    35\n",
      "1    31\n",
      "6    20\n",
      "2    17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data\n",
    "cols = ['name','landmass','zone', 'area', 'population', 'language','religion','bars','stripes','colours',\n",
    "'red','green','blue','gold','white','black','orange','mainhue','circles',\n",
    "'crosses','saltires','quarters','sunstars','crescent','triangle','icon','animate','text','topleft','botright']\n",
    "df= pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data\", names = cols)\n",
    "\n",
    "#variable names to use as predictors\n",
    "var = [ 'red', 'green', 'blue','gold', 'white', 'black', 'orange', 'mainhue','bars','stripes', 'circles','crosses', 'saltires','quarters','sunstars','triangle','animate']\n",
    "\n",
    "#Print number of countries by landmass, or continent\n",
    "print(df.landmass.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rather than looking at all six continents, we will focus on just two, Europe and Oceania. Create a new dataframe with only flags from Europe and Oceania.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with only flags from Europe and Oceania\n",
    "df_36 = df[df[\"landmass\"].isin([3,6])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Given the list of predictors in the list var, print the average values of each for these two continents. Note which predictors have very different averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert redgoldredgoldredwhitewhiteredwhitewhitewhitegoldblackwhiteblueredbluewhitewhiteredredredredredredwhiteredredwhiteredblueredredgoldred to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39maggregate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[39mreturn\u001b[39;00m cy_op\u001b[39m.\u001b[39;49mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[39m=\u001b[39;49mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mT\n\u001b[1;32m--> 497\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_cython_op(\n\u001b[0;32m    498\u001b[0m     values,\n\u001b[0;32m    499\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[0;32m    500\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[0;32m    501\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[0;32m    502\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    503\u001b[0m     result_mask\u001b[39m=\u001b[39;49mresult_mask,\n\u001b[0;32m    504\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    505\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cython_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkind, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow, values\u001b[39m.\u001b[39;49mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[39m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunction is not implemented for this dtype: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[how->\u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m,dtype->\u001b[39m\u001b[39m{\u001b[39;00mdtype_str\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(x)\n\u001b[0;32m   1693\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[39m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'redgoldredgoldredwhitewhiteredwhitewhitewhitegoldblackwhiteblueredbluewhitewhiteredredredredredredwhiteredredwhiteredblueredredgoldred'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39;49m(x)\n\u001b[0;32m   1697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[39m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Print the average vales of the predictors for Europe and Oceania\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(df_36\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mlandmass\u001b[39;49m\u001b[39m'\u001b[39;49m)[var]\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39mT)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1857\u001b[0m         alt\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim, alt\u001b[39m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m blk\u001b[39m.\u001b[39mis_object:\n\u001b[0;32m   1500\u001b[0m     \u001b[39m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[39m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[39mfor\u001b[39;00m sb \u001b[39min\u001b[39;00m blk\u001b[39m.\u001b[39m_split():\n\u001b[1;32m-> 1503\u001b[0m         applied \u001b[39m=\u001b[39m sb\u001b[39m.\u001b[39;49mapply(func)\n\u001b[0;32m   1504\u001b[0m         result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1505\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim, alt\u001b[39m=\u001b[39;49malt)\n\u001b[0;32m   1505\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[39m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[39m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[39m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(ser, alt, preserve_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[39m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[39m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[39m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(values)\u001b[39m.\u001b[39m_from_sequence(res_values, dtype\u001b[39m=\u001b[39mvalues\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39m_values, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[39m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[39m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[39m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[39m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_splitter(obj, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[39m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[39m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not allow \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnumeric_only\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith non-numeric dtypes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[39m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert redgoldredgoldredwhitewhiteredwhitewhitewhitegoldblackwhiteblueredbluewhitewhiteredredredredredredwhiteredredwhiteredblueredredgoldred to numeric"
     ]
    }
   ],
   "source": [
    "#Print the average vales of the predictors for Europe and Oceania\n",
    "print(df_36.groupby('landmass')[var].mean().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We will build a classifier to distinguish flags for these two continents – but first, inspect the variable types for each of the predictors.\n",
    "\n",
    "    ```python\n",
    "    labels = (df[\"landmass\"].isin([3,6]))*1\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labels for only Europe and Oceania\n",
    "labels = (df[\"landmass\"].isin([3,6]))*1\n",
    "\n",
    "#Print the variable types for the predictors\n",
    "print(df[var].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Note that all the predictor variables are numeric except for mainhue. Transform the dataset of predictor variables to dummy variables and save this in a new dataframe called data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables for categorical predictors\n",
    "data = pd.get_dummies(df_36[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Split the data into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into a train and test set\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=1, test_size=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Decision Tree Classifiers by Depth\n",
    "\n",
    "7. We will explore tuning the decision tree model by testing the performance over a range of `max_depth` values. Fit a decision tree classifier for `max_depth` values from 1-20. Save the accuracy score in for each depth in the list `acc_depth`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a decision tree for max_depth values 1-20; save the accuracy score in acc_depth\n",
    "depths = range(1, 21)\n",
    "acc_depth = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Plot the accuracy of the decision tree models versus the `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the accuracy vs depth\n",
    "for i in depths:\n",
    "    dt = DecisionTreeClassifier(random_state = 10, max_depth = i)\n",
    "    dt.fit(train_data, train_labels)\n",
    "    acc_depth.append(dt.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find the largest accuracy and the depth this occurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the largest accuracy and the depth this occurs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Refit the decision tree model using the `max_depth` from above; plot the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refit decision tree model with the highest accuracy and plot the decision tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Decision Tree Classifiers by Pruning\n",
    "\n",
    "11. Like we did with max_depth, we will now tune the tree by using the hyperparameter `ccp_alpha`, which is a pruning parameter. Fit a decision tree classifier for each value in ccp. Save the accuracy score in the list `acc_pruned`.\n",
    "12. Plot the accuracy of the decision tree models versus the `ccp_alpha`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list for the accuracy values of a pruned decision tree.\n",
    "# Loop through the values of ccp and append the scores to the list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Find the largest accuracy and the `ccp_alpha` value this occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the accuracy vs ccp_alpha\n",
    "\n",
    "\n",
    "#Find the largest accuracy and the ccp value this occurs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Fit a decision tree model with the values for `max_depth` and `ccp_alpha` found above. Plot the final decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a decision tree model with the values for max_depth and ccp_alpha found above\n",
    "\n",
    "\n",
    "#Plot the final decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Nice work! Note that the accuracy of our final model increased and the structure of the tree was simpler – many unnecessary branches were removed in the pruning process making for a much easier interpretation.\n",
    "\n",
    "    There are a few different ways to extend this project:\n",
    "\n",
    "    Try to classify something else! Rather than predicting the \"Landmass\" feature, you could predict something like the \"Language\"?\n",
    "\n",
    "    Find a subset of features that work better than what we’re currently using. An important note is that a feature that has categorical data won’t work very well as a feature. For example, we don't want a decision node to split nodes based on whether the value for \"Language\" is above or below 5.\n",
    "\n",
    "    Tune more parameters of the model. You can find a description of all the parameters you can tune in the Decision Tree Classifier documentation. For example, see what happens if you tune `max_leaf_nodes`. Think about whether you would be overfitting or underfitting the data based on how many leaf nodes you allow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# Load the data and define the predictors\n",
    "cols = ['name','landmass','zone', 'area', 'population', 'language','religion','bars','stripes','colours',\n",
    "        'red','green','blue','gold','white','black','orange','mainhue','circles',\n",
    "        'crosses','saltires','quarters','sunstars','crescent','triangle','icon','animate','text','topleft','botright']\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data\", names=cols)\n",
    "\n",
    "var = ['red', 'green', 'blue','gold', 'white', 'black', 'orange', 'mainhue','bars','stripes',\n",
    "       'circles','crosses', 'saltires','quarters','sunstars','triangle','animate']\n",
    "\n",
    "# Print number of countries by landmass\n",
    "print(df.landmass.value_counts())\n",
    "\n",
    "# Create a new dataframe with only flags from Europe and Oceania\n",
    "df_36 = df[df[\"landmass\"].isin([3, 6])]\n",
    "\n",
    "# Print the average values of the predictors for Europe and Oceania\n",
    "print(df_36.groupby('landmass')[var].mean().T)\n",
    "\n",
    "# Create labels for only Europe and Oceania\n",
    "labels = (df[\"landmass\"].isin([3, 6])) * 1\n",
    "\n",
    "# Print the variable types for the predictors\n",
    "print(df[var].dtypes)\n",
    "\n",
    "# Create dummy variables for categorical predictors\n",
    "data = pd.get_dummies(df_36[var])\n",
    "\n",
    "# Split data into a train and test set\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=1, test_size=.4)\n",
    "\n",
    "# Fit a decision tree for max_depth values 1-20; save the accuracy score in acc_depth\n",
    "depths = range(1, 21)\n",
    "acc_depth = []\n",
    "\n",
    "# Plot the accuracy vs depth\n",
    "for i in depths:\n",
    "    dt = DecisionTreeClassifier(random_state=10, max_depth=i)\n",
    "    dt.fit(train_data, train_labels)\n",
    "    acc_depth.append(dt.score(test_data, test_labels))\n",
    "\n",
    "# Plot the accuracy of the decision tree models versus the max_depth\n",
    "plt.plot(depths, acc_depth)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs max_depth\")\n",
    "plt.show()\n",
    "\n",
    "# Find the largest accuracy and the depth this occurs\n",
    "max_accuracy = max(acc_depth)\n",
    "best_depth = acc_depth.index(max_accuracy) + 1\n",
    "print(\"Best accuracy:\", max_accuracy)\n",
    "print(\"Best depth:\", best_depth)\n",
    "\n",
    "# Refit decision tree model with the highest accuracy and plot the decision tree\n",
    "dt_best = DecisionTreeClassifier(random_state=10, max_depth=best_depth)\n",
    "dt_best.fit(train_data, train_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "tree.plot_tree(dt_best, feature_names=data.columns, class_names=[\"Other\", \"Europe/Oceania\"], filled=True)\n",
    "plt.show()\n",
    "\n",
    "# Create a new list for the accuracy values of a pruned decision tree\n",
    "acc_pruned = []\n",
    "\n",
    "# Loop through the values of ccp_alpha and append the scores to the list\n",
    "ccp_alphas = np.linspace(0, 0.1, 100)\n",
    "for alpha in ccp_alphas:\n",
    "    dt = DecisionTreeClassifier(random_state=10, ccp_alpha=alpha)\n",
    "    dt.fit(train_data, train_labels)\n",
    "    acc_pruned.append(dt.score(test_data, test_labels))\n",
    "\n",
    "# Plot the accuracy of the decision tree models versus the ccp_alpha\n",
    "plt.plot(ccp_alphas, acc_pruned)\n",
    "plt.xlabel(\"ccp_alpha\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs ccp_alpha\")\n",
    "plt.show()\n",
    "\n",
    "# Find the largest accuracy and the ccp_alpha value this occurs\n",
    "max_accuracy = max(acc_pruned)\n",
    "best_alpha = ccp_alphas[acc_pruned.index(max_accuracy)]\n",
    "print(\"Best accuracy:\", max_accuracy)\n",
    "print(\"Best ccp_alpha:\", best_alpha)\n",
    "\n",
    "# Fit a decision tree model with the values for max_depth and ccp_alpha found above\n",
    "dt_final = DecisionTreeClassifier(random_state=10, max_depth=best_depth, ccp_alpha=best_alpha)\n",
    "dt_final.fit(train_data, train_labels)\n",
    "\n",
    "# Plot the final decision tree\n",
    "plt.figure(figsize=(10, 8))\n",
    "tree.plot_tree(dt_final, feature_names=data.columns, class_names=[\"Other\", \"Europe/Oceania\"], filled=True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
